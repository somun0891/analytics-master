# ======
# Globals
# ======

variables:
  PYTHONPATH: "$CI_PROJECT_DIR/orchestration/:$CI_PROJECT_DIR/extract/:$CI_PROJECT_DIR/extract/shared_modules/:$PYTHONPATH"
  BRANCH_NAME: "$CI_COMMIT_REF_NAME"

# ======
# Workflows
# ======
# Rules explaination: https://docs.gitlab.com/ee/ci/yaml/workflow.html#switch-between-branch-pipelines-and-merge-request-pipelines

workflow:
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS && $CI_PIPELINE_SOURCE == "push"
      when: never
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
      when: never
    - if: $CI_COMMIT_BRANCH

# ======
# CI Stages
# ======
stages:
  - ‚ùÑÔ∏è Snowflake
  - üöÇ Extract   # extract/extract-ci.yml
  - ‚öôÔ∏è dbt Run    # transform/snowflake-dbt/snowflake-dbt-ci.yml
  - üõ† dbt Misc  # transform/snowflake-dbt/snowflake-dbt-ci.yml
  - üìö dbt Docs
  - üõëüêç Python Critical
  - üêç Python
  - üõë Snowflake Stop
  - triage
  - triage run

include:
  -  template: Jobs/Secret-Detection.gitlab-ci.yml
  - "extract/extract-ci.yml"
  - "transform/snowflake-dbt/snowflake-dbt-ci.yml"

secret_detection:
  stage: üõëüêç Python Critical
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  allow_failure: false
  variables:
    SECRET_DETECTION_EXCLUDED_PATHS: "docker-compose.yml, transform/snowflake-dbt/packages.yml, extract/saas_postgres_pipeline_backfill/postgres_pipeline/postgres_utils.py"

# ======
# Snowflake Database Clones
# ======

# Template for cloning databases in Snowflake for use in MRs
.snowflake_clone_template: &snowflake_clone_template
  image: registry.gitlab.com/gitlab-data/data-image/data-image:v0.0.13
  tags:
    - analytics
  before_script:
    - export PATH="$CI_PROJECT_DIR/orchestration/:$PATH"
  only:
    refs:
      - merge_requests
    variables:
      - $SNOWFLAKE_SYSADMIN_ROLE
      - $SNOWFLAKE_LOAD_WAREHOUSE
      - $SNOWFLAKE_LOAD_DATABASE  # make sure the guard works
      - $SNOWFLAKE_PREP_DATABASE  # make sure the guard works
      - $SNOWFLAKE_PROD_DATABASE  # make sure the guard works
  except:
    refs:
      - master
    variables:
      - $BRANCH_NAME == $SNOWFLAKE_LOAD_DATABASE
      - $BRANCH_NAME == $SNOWFLAKE_PREP_DATABASE
      - $BRANCH_NAME == $SNOWFLAKE_PROD_DATABASE
      - $TEST_PIPELINE
  when: manual

.snowflake_start_clone: &snowflake_start_clone
  <<: *snowflake_clone_template
  environment:
    name: review/$CI_COMMIT_REF_NAME
    on_stop: clone_stop
  stage: ‚ùÑÔ∏è Snowflake
  variables:
    GIT_STRATEGY: clone

# Clone Jobs
üìàclone_prod:
  <<: *snowflake_start_clone
  script:
    - manage_snowflake.py manage_clones --database prod --empty
    - manage_snowflake.py manage_clones --database prep --empty
    - manage_snowflake.py manage_clones --database raw --empty
  when: always

üìà‚ùóÔ∏èclone_prod_real:
  <<: *snowflake_start_clone
  script:
    - manage_snowflake.py manage_clones --force --database prod
    - manage_snowflake.py manage_clones --force --database prep

üìà‚öôclone_prep_specific_schema:
  <<: *snowflake_start_clone
  script:
    - manage_snowflake.py manage_clones --database prep --schema $SCHEMA_NAME

üìà‚öôclone_prod_specific_schema:
  <<: *snowflake_start_clone
  script:
    - manage_snowflake.py manage_clones --database prod --schema $SCHEMA_NAME

ü•©clone_raw_full:
  <<: *snowflake_start_clone
  script:
    - manage_snowflake.py manage_clones --database raw --include_stages

ü•©üìúclone_raw_sheetload:
  <<: *snowflake_start_clone
  script:
    - manage_snowflake.py manage_clones --database raw --schema sheetload

ü•©üõ¢clone_raw_postgres_pipeline:
  <<: *snowflake_start_clone
  script:
    - manage_snowflake.py manage_clones --database raw --schema tap_postgres

ü•©‚öôclone_raw_specific_schema:
  <<: *snowflake_start_clone
  script:
    - manage_snowflake.py manage_clones --database raw --schema $SCHEMA_NAME --include_stages

üë•force_clone_both:
  <<: *snowflake_start_clone
  script:
    - manage_snowflake.py manage_clones --force --database prep --empty
    - manage_snowflake.py manage_clones --force --database prod --empty
    - manage_snowflake.py manage_clones --force --database raw --include_stages

clone_raw_by_schema:
  <<: *snowflake_start_clone
  script:
    - manage_snowflake.py clone_database_by_schemas --database raw --include_stages

clone_stop:
  <<: *snowflake_clone_template
  stage: üõë Snowflake Stop
  environment:
    name: review/$CI_COMMIT_REF_NAME
    action: stop
  variables:
    GIT_STRATEGY: none
  dependencies: []
  script:
    - git clone $CI_REPOSITORY_URL
    - analytics/orchestration/manage_snowflake.py delete_clones

üîëgrant_clones:
  <<: *snowflake_start_clone
  script:
    - manage_snowflake.py grant_clones --database prod --role $GRANT_TO_ROLE
    - manage_snowflake.py grant_clones --database prep --role $GRANT_TO_ROLE

# ======
# Python Code Checks
# ======

.python_critical_check: &python_critical_check
  stage: üõëüêç Python Critical
  image: registry.gitlab.com/gitlab-data/ci-python-image:v0.0.4
  before_script:
    - CHANGED_FILES=$(git diff --name-only ${CI_COMMIT_SHA} origin/${CI_MERGE_REQUEST_TARGET_BRANCH_NAME} | grep '\.py\|\.ipynb'$)
  tags:
    - analytics
  only:
    changes:
      - "**/*.py"
      - "**/*.ipynb"
    refs:
      - merge_requests
  allow_failure: false

.python_check: &python_check
  stage: üêç Python
  image: registry.gitlab.com/gitlab-data/ci-python-image:v0.0.4
  before_script:
    - CHANGED_FILES=$(git diff --name-only --diff-filter=d origin/${CI_MERGE_REQUEST_TARGET_BRANCH_NAME} ${CI_COMMIT_SHA} | grep '\.py'$)
  tags:
    - analytics
  only:
    changes:
      - "**/*.py"
    refs:
      - merge_requests
  allow_failure: true

.python_testing: &python_testing
  stage: üêç Python
  tags:
    - analytics
  image: registry.gitlab.com/gitlab-data/data-image/data-image:v2.0.8
  only:
    changes:
      - "**/*.py"
    refs:
      - merge_requests
  allow_failure: true

‚ö´python_black:
  <<: *python_critical_check
  script:
    - black --check .

‚úèÔ∏èpython_mypy:
  <<: *python_critical_check
  script:
    - mypy extract/ --ignore-missing-imports --explicit-package-bases --implicit-optional

üåΩpython_flake8:
  <<: *python_check
  script:
    - echo "Changed files are $CHANGED_FILES"
    - flake8 $CHANGED_FILES --ignore=E203,E501,W503,W605

üóíÔ∏èpython_pylint:
  <<: *python_check
  script:
    - echo "Changed files are $CHANGED_FILES"
    - pylint $CHANGED_FILES --ignore=analytics/dags --disable=line-too-long,E0401,E0611,W1203,W1202,C0103,R0801,R0902,W0212,W0104,W0106,W0703

ü§îpython_complexity:
  <<: *python_check
  script:
    - xenon --max-absolute B --max-modules B --max-average A . -i transform,shared_modules

ü¶Öpython_vulture:
  <<: *python_check
  script:
    - echo "Changed files are $CHANGED_FILES"
    - vulture $CHANGED_FILES --min-confidence 100

‚úÖpython_pytest:
  <<: *python_testing
  script:
    - export GCP_SERVICE_CREDS=$(echo "$ENCODED_GCP" | base64 -d)
    - python -m pytest -vv -x --junitxml=report.xml
  artifacts:
    reports:
      junit: ${CI_PROJECT_DIR}/report.xml
    paths:
      - ${CI_PROJECT_DIR}/.coverage.${CI_JOB_ID}
    expire_in: 1 day
    when: on_success

# ======
# Snowflake Permissions Validator
# ======

.yaml_validate: &yaml_validate
  stage: üêç Python
  image: registry.gitlab.com/gitlab-data/data-image/data-image:v0.0.13
  tags:
    - analytics
  only:
    changes:
      - "permissions/snowflake/roles.yml"
      - "permissions/snowflake/snowflake_usernames.yml"
    refs:
      - merge_requests
  allow_failure: true
  before_script:
    - CHANGED_FILES=$(git diff --name-only --diff-filter=d origin/${CI_MERGE_REQUEST_TARGET_BRANCH_NAME} ${CI_COMMIT_SHA} | grep '\.yml\|\.yaml'$)

üìÅyaml_validation:
  <<: *yaml_validate
  script: |
    # Iterate over each changed YAML file using Python's yaml.safe_load
    for file in $CHANGED_FILES; do
      if python -c "import yaml; yaml.safe_load(open('$file'))" > /dev/null 2>&1; then
        echo "YAML validation passed for $file"
      else
        echo "YAML validation failed for $file"
        exit 1
      fi
    done;
  allow_failure: false

.permifrost: &permifrost
  stage: üêç Python
  image: registry.gitlab.com/gitlab-data/permifrost:v0.15.4
  tags:
    - analytics
  only:
    changes:
      - "permissions/snowflake/roles.yml"
    refs:
      - merge_requests
  allow_failure: true

üßä‚öôpermifrost_run:
  <<: *permifrost
  script:
    - permifrost run permissions/snowflake/roles.yml --diff --dry
  when: manual
  allow_failure: true

üßäpermifrost_spec_test:
  <<: *permifrost
  script:
    - permifrost spec-test permissions/snowflake/roles.yml
  when: manual
  allow_failure: true

.snowflake_provisioning_automation: &snowflake_provisioning_automation
  stage: üêç Python
  image: registry.gitlab.com/gitlab-data/data-image/data-image:v2.0.7
  tags:
    - analytics
  before_script:
    - cd orchestration/snowflake_provisioning_automation/

    # shared arguments
    - export IS_TEST_RUN_FINAL="--no-test-run"
    - if [ -n "$IS_TEST_RUN" ]; then IS_TEST_RUN_FINAL="--test-run"; fi

    - export USERS_TO_ADD_FINAL=""
    - if [ -n "$USERS_TO_ADD" ]; then USERS_TO_ADD_FINAL="--users-to-add $USERS_TO_ADD"; fi

  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  when: manual
  allow_failure: true

snowflake_provisioning_snowflake_users:
  <<: *snowflake_provisioning_automation
  rules:
    # only allow trigger if MR approved
    - if: '$CI_MERGE_REQUEST_APPROVED == "true"'
      when: manual
  script:
    # provision_users.py specific argument
    - export IS_DEV_DB_FINAL=""
    - if [ -n "$IS_DEV_DB" ]; then IS_DEV_DB_FINAL="--dev-db"; fi

    - echo "Below are CI job arguments, missing key/values will use default Python values:"
    - echo -e "IS_TEST_RUN=$IS_TEST_RUN_FINAL\n\
               IS_DEV_DB=$IS_DEV_DB_FINAL"

    - python3 provision_users/provision_users.py $IS_TEST_RUN_FINAL $IS_DEV_DB_FINAL

snowflake_provisioning_roles_yaml:
  <<: *snowflake_provisioning_automation
  script:
    # update_roles_yaml.py specific arguments below
    - export USERS_TO_REMOVE_FINAL=""
    - if [ -n "$USERS_TO_REMOVE" ]; then USERS_TO_REMOVE_FINAL="--users-to-remove $USERS_TO_REMOVE"; fi

    - export DATABASES_TEMPLATE_FINAL=""
    - if [ -n "$DATABASES_TEMPLATE" ]; then DATABASES_TEMPLATE_FINAL="$DATABASES_TEMPLATE"; fi

    - export ROLES_TEMPLATE_FINAL=""
    - if [ -n "$ROLES_TEMPLATE" ]; then ROLES_TEMPLATE_FINAL="$ROLES_TEMPLATE"; fi

    - export USERS_TEMPLATE_FINAL=""
    - if [ -n "$USERS_TEMPLATE" ]; then USERS_TEMPLATE_FINAL="$USERS_TEMPLATE"; fi

    - echo "Below are CI job arguments, missing key/values will use default Python values:"
    - echo -e "IS_TEST_RUN=$IS_TEST_RUN_FINAL\n\
      USERS_TO_ADD=$USERS_TO_ADD_FINAL\n\
      USERS_TO_REMOVE=$USERS_TO_REMOVE_FINAL\n\
      DATABASES_TEMPLATE=$DATABASES_TEMPLATE_FINAL\n\
      ROLES_TEMPLATE=$ROLES_TEMPLATE_FINAL\n\
      USERS_TEMPLATE=$USERS_TEMPLATE_FINAL"

    - python3 update_roles_yaml/update_roles_yaml.py $IS_TEST_RUN_FINAL $USERS_TO_ADD_FINAL $USERS_TO_REMOVE_FINAL --databases-template "$DATABASES_TEMPLATE_FINAL" --roles-template "$ROLES_TEMPLATE_FINAL" --users-template "$USERS_TEMPLATE_FINAL"

    # If there are changes to roles.yml, then commit/push back to repo
    - if [[ -n $(git status --porcelain) ]]; then
      git config user.email "analyticsapi@gitlab.com";
      git config user.name "snowflake_provisioning_automation";
      git remote add gitlab_origin https://oauth2:$SNOWFLAKE_PROVISIONING_AUTOMATION_PROJECT_ACCESS_TOKEN@gitlab.com/gitlab-data/analytics.git;
      cd $(git rev-parse --show-toplevel);
      git add permissions/snowflake/roles.yml;
      git commit -m "pushed from `snowflake_provisioning_roles_yaml` job";
      git push gitlab_origin HEAD:$BRANCH_NAME;
      else
        echo "Nothing to commit. Check if 'snowflake_users.yml' was updated. Aborting.";
      fi

# ======
# dbt docs to GitLab Pages
# ======

.pages_job_template: &pages_job_template
  stage: üìö dbt Docs
  image: registry.gitlab.com/gitlab-data/dbt-image:v0.0.7
  variables:
    SNOWFLAKE_ROLE: $SNOWFLAKE_TRANSFORM_ROLE
    SNOWFLAKE_WAREHOUSE: $SNOWFLAKE_TRANSFORM_WAREHOUSE
  before_script:
    - export PATH="$CI_PROJECT_DIR/orchestration/:$PATH"
  script:
    - export SNOWFLAKE_SNAPSHOT_DATABASE="RAW"
    - echo $SNOWFLAKE_SNAPSHOT_DATABASE
    - mkdir -p ~/.ssh
    - touch ~/.ssh/id_rsa
    - chmod 700 ~/.ssh
    - echo "$GIT_DATA_TESTS_SSH_PRIVATE_KEY" | base64 --decode > ~/.ssh/id_rsa # decodes key from base64
    - chmod 0400 ~/.ssh/id_rsa # Makes key read only
    - echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config # Adds gitlab.com as known host
    - cd $CI_PROJECT_DIR/transform/snowflake-dbt/
    - rm packages.yml
    - mv docs-packages.yml packages.yml
    - export DBT_RUNNER="${GITLAB_USER_ID}-0-${CI_JOB_ID}"
    - echo $DBT_RUNNER
    - dbt deps --profiles-dir profile --target prod
    - dbt docs generate --profiles-dir profile --target prod
    - mkdir -p $CI_PROJECT_DIR/public/
    - cd target
    - | # remove row counts
      sed -i 's/"Row Count", "value": [0-9]*/"Row Count", "value": -1/g' catalog.json
    - cp *.json graph.gpickle $CI_PROJECT_DIR/public/
    - cd $CI_PROJECT_DIR/transform/snowflake-dbt/docs/
    - cp index.html gitlab.css $CI_PROJECT_DIR/public/
  tags:
    - analytics
  artifacts:
    name: "dbt Docs Files"
    paths:
      - public
    expire_in: 1 week


# Run the script to generate the dbt docs and stand them up in gitlab pages
pages:
  <<: *pages_job_template
  only:
    changes:
      - "transform/snowflake-dbt/*"
    refs:
      - master
    variables:
      - $DEPLOY_DBT_PAGES

dry-run:triage:
    image: ruby:2.4
    stage: triage
    script:
      - gem install gitlab-triage
      - gitlab-triage --help
      - gitlab-triage --dry-run --token $ANALYTICS_API_TOKEN --source projects --source-id $CI_PROJECT_PATH
    when: manual
    except:
      - schedules

policy:run-triage:
    image: ruby:2.4
    stage: triage run
    script:
      - gem install gitlab-triage
      - gitlab-triage --token $ANALYTICS_API_TOKEN --source projects --source-id $CI_PROJECT_PATH
    only:
      refs:
        - master
    when: manual
    except:
      - schedules

schedule:run-triage:
    image: ruby:2.4
    stage: triage run
    script:
      - gem install gitlab-triage
      - gitlab-triage --token $ANALYTICS_API_TOKEN --source projects --source-id $CI_PROJECT_PATH
    only:
      variables:
        - $RUN_GITLAB_TRIAGE

